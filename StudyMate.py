# -*- coding: utf-8 -*-
"""Untitled3.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1H886DbBffDqWReaj1GKxpbwhWhl0xF15
"""

# Study Mate Chatbot - Complete Implementation
# Copy and paste this entire code into a single Google Colab cell

# Step 1: Install required packages
!pip install -q gradio transformers torch PyPDF2 gtts accelerate

# Step 2: Import libraries
import gradio as gr
import torch
from transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig
import PyPDF2
from gtts import gTTS
import os
import re
from datetime import datetime
import json

# Step 3: Load IBM Granite 3.3 2B Instruct Model with Optimization
print("Loading IBM Granite 3.3 2B Instruct model (optimized)...")
model_name = "ibm-granite/granite-3.0-2b-instruct"

# Check if GPU is available
device = "cuda" if torch.cuda.is_available() else "cpu"
print(f"Using device: {device}")

tokenizer = AutoTokenizer.from_pretrained(model_name)

# Optimized model loading
if device == "cuda":
    # Use 8-bit quantization for faster inference on GPU
    model = AutoModelForCausalLM.from_pretrained(
        model_name,
        torch_dtype=torch.float16,
        device_map="auto",
        low_cpu_mem_usage=True
    )
else:
    # CPU optimization
    model = AutoModelForCausalLM.from_pretrained(
        model_name,
        torch_dtype=torch.float32,
        low_cpu_mem_usage=True
    )
    model = model.to(device)

print("Model loaded successfully!")

# Global variable to store PDF content
pdf_text_content = ""

# Step 4: PDF Processing Function
def extract_text_from_pdf(pdf_file):
    """Extract text from uploaded PDF file"""
    global pdf_text_content
    try:
        pdf_reader = PyPDF2.PdfReader(pdf_file.name)
        text = ""
        for page in pdf_reader.pages:
            text += page.extract_text() + "\n"
        pdf_text_content = text
        return f"‚úÖ PDF uploaded successfully! Extracted {len(text)} characters from {len(pdf_reader.pages)} pages."
    except Exception as e:
        return f"‚ùå Error reading PDF: {str(e)}"

# Step 5: Generate Response Function (Optimized)
def generate_response(prompt, max_length=300):
    """Generate response using IBM Granite model - OPTIMIZED"""
    try:
        messages = [
            {"role": "user", "content": prompt}
        ]

        input_text = tokenizer.apply_chat_template(messages, tokenize=False, add_generation_prompt=True)
        inputs = tokenizer(input_text, return_tensors="pt", truncation=True, max_length=2048).to(model.device)

        # Optimized generation parameters for speed
        outputs = model.generate(
            **inputs,
            max_new_tokens=max_length,
            temperature=0.7,
            top_p=0.9,
            do_sample=True,
            num_beams=1,  # Faster: no beam search
            pad_token_id=tokenizer.eos_token_id,
            use_cache=True  # Enable KV cache for faster generation
        )

        response = tokenizer.decode(outputs[0], skip_special_tokens=True)
        # Extract only the assistant's response
        if "assistant" in response:
            response = response.split("assistant")[-1].strip()
        elif "Answer:" in response:
            response = response.split("Answer:")[-1].strip()

        return response
    except Exception as e:
        return f"Error: {str(e)}"

# Feature 1 & 3: Chatbot with PDF Q&A (Optimized)
def chatbot_response(message, history):
    """Main chatbot function that answers questions based on PDF content"""
    global pdf_text_content

    if not pdf_text_content:
        response = "‚ö†Ô∏è Please upload a PDF first to ask questions about it!"
    else:
        # Reduced context window for faster processing
        prompt = f"""Based on the document, answer concisely.

Document: {pdf_text_content[:2000]}

Question: {message}

Answer:"""

        response = generate_response(prompt, max_length=200)

    # Return history in correct format
    history = history or []
    history.append([message, response])
    return history, ""

# Feature 4: Generate Summary (Optimized)
def generate_summary():
    """Generate a comprehensive summary of the PDF content"""
    global pdf_text_content

    if not pdf_text_content:
        return "‚ö†Ô∏è Please upload a PDF first!"

    prompt = f"""Summarize this document in 3-4 key points:

{pdf_text_content[:2500]}

Summary:"""

    summary = generate_response(prompt, max_length=350)
    return summary

# Feature 5: Create Study Plan (Optimized)
def create_study_plan():
    """Generate a study plan based on PDF content"""
    global pdf_text_content

    if not pdf_text_content:
        return "‚ö†Ô∏è Please upload a PDF first!"

    prompt = f"""Create a concise study plan with main topics and sequence:

{pdf_text_content[:2500]}

Study Plan:"""

    study_plan = generate_response(prompt, max_length=400)
    return study_plan

# Feature 6: Generate Flashcards (Optimized)
def generate_flashcards():
    """Generate flashcards with terms and definitions"""
    global pdf_text_content

    if not pdf_text_content:
        return "‚ö†Ô∏è Please upload a PDF first!"

    prompt = f"""Create 8 flashcards in this format:
TERM: [term]
DEFINITION: [definition]

{pdf_text_content[:2500]}

Flashcards:"""

    flashcards = generate_response(prompt, max_length=500)
    return flashcards

# Feature 7: Generate Examples and Problems (Optimized)
def generate_examples():
    """Generate practice examples and problems"""
    global pdf_text_content

    if not pdf_text_content:
        return "‚ö†Ô∏è Please upload a PDF first!"

    prompt = f"""Generate 3 practice problems with brief solutions:

{pdf_text_content[:2500]}

Problems:"""

    examples = generate_response(prompt, max_length=450)
    return examples

# Feature 8: Voice-Based Explanation
def generate_voice_explanation(text_to_speak):
    """Convert text to speech for voice explanation"""
    try:
        if not text_to_speak or text_to_speak.strip() == "":
            return "‚ö†Ô∏è Please enter text to convert to speech!"

        # Generate speech
        tts = gTTS(text=text_to_speak, lang='en', slow=False)
        audio_file = "explanation.mp3"
        tts.save(audio_file)

        return audio_file
    except Exception as e:
        return f"Error generating voice: {str(e)}"

def quick_explain_topic(topic):
    """Generate a quick explanation of a topic from the PDF"""
    global pdf_text_content

    if not pdf_text_content:
        return "‚ö†Ô∏è Please upload a PDF first!", None

    prompt = f"""Based on this document, provide a clear and simple explanation of: {topic}

Document:
{pdf_text_content[:3000]}...

Explanation:"""

    explanation = generate_response(prompt, max_length=400)
    audio_file = generate_voice_explanation(explanation)

    return explanation, audio_file

# Step 6: Create Gradio Interface
with gr.Blocks(title="Study Mate Chatbot", theme=gr.themes.Soft()) as demo:

    gr.Markdown("""
    # üìö Study Mate Chatbot
    ### Your AI-Powered Study Assistant with IBM Granite 3.3 2B
    Upload a PDF and explore 8 powerful features to enhance your learning!
    """)

    # PDF Upload Section
    with gr.Row():
        with gr.Column():
            pdf_input = gr.File(label="üìÑ Upload Your Study Material (PDF)", file_types=[".pdf"])
            upload_status = gr.Textbox(label="Upload Status", interactive=False)
            pdf_input.change(extract_text_from_pdf, inputs=pdf_input, outputs=upload_status)

    gr.Markdown("---")

    # Tabs for different features
    with gr.Tabs():

        # Tab 1: Chatbot Q&A
        with gr.Tab("üí¨ Chat & Ask Questions"):
            gr.Markdown("### Ask questions about your PDF content")
            chatbot = gr.Chatbot(height=400)
            msg = gr.Textbox(label="Your Question", placeholder="Ask anything about the PDF...")
            clear = gr.Button("Clear Chat")

            msg.submit(chatbot_response, [msg, chatbot], [chatbot, msg])
            clear.click(lambda: [], None, chatbot)

        # Tab 2: Summary
        with gr.Tab("üìù Generate Summary"):
            gr.Markdown("### Get a comprehensive summary of your document")
            summary_btn = gr.Button("Generate Summary", variant="primary")
            summary_output = gr.Textbox(label="Summary", lines=12)
            summary_btn.click(generate_summary, outputs=summary_output)

        # Tab 3: Study Plan
        with gr.Tab("üìÖ Create Study Plan"):
            gr.Markdown("### Get a personalized study plan based on your material")
            study_plan_btn = gr.Button("Create Study Plan", variant="primary")
            study_plan_output = gr.Textbox(label="Study Plan", lines=12)
            study_plan_btn.click(create_study_plan, outputs=study_plan_output)

        # Tab 4: Flashcards
        with gr.Tab("üé¥ Generate Flashcards"):
            gr.Markdown("### Automatically create flashcards for memorization")
            flashcard_btn = gr.Button("Generate Flashcards", variant="primary")
            flashcard_output = gr.Textbox(label="Flashcards", lines=12)
            flashcard_btn.click(generate_flashcards, outputs=flashcard_output)

        # Tab 5: Practice Problems
        with gr.Tab("‚úèÔ∏è Practice Problems"):
            gr.Markdown("### Generate examples and practice problems")
            examples_btn = gr.Button("Generate Problems", variant="primary")
            examples_output = gr.Textbox(label="Practice Problems", lines=12)
            examples_btn.click(generate_examples, outputs=examples_output)

        # Tab 6: Voice Explanation
        with gr.Tab("üîä Voice Explanation"):
            gr.Markdown("### Get audio explanations of topics")
            topic_input = gr.Textbox(label="Enter topic to explain", placeholder="e.g., photosynthesis, Newton's laws, etc.")
            explain_btn = gr.Button("Get Voice Explanation", variant="primary")
            explanation_text = gr.Textbox(label="Explanation", lines=6)
            audio_output = gr.Audio(label="Audio Explanation")
            explain_btn.click(quick_explain_topic, inputs=topic_input, outputs=[explanation_text, audio_output])

    gr.Markdown("""
    ---
    ### üéØ Features:
    1. **Chatbot** - Ask any question about your PDF
    2. **PDF Upload** - Support for PDF documents
    3. **Q&A** - Get answers from your study material
    4. **Summary** - Automatic document summarization
    5. **Study Plan** - Personalized learning schedule
    6. **Flashcards** - Auto-generated term/definition cards
    7. **Practice Problems** - Examples and exercises with solutions
    8. **Voice Explanation** - Audio explanations of topics

    **Powered by IBM Granite 3.3 2B Instruct Model**
    """)

# Step 7: Launch the application
print("\n" + "="*50)
print("üöÄ Launching Study Mate Chatbot...")
print("="*50 + "\n")

demo.launch(debug=False, share=True)